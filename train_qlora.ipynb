{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9219fd49943942f7857b51ac96999671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79225840e5ba45a2970402d891a10f02",
              "IPY_MODEL_d12899ffd89b41729b08647895a7b4c0",
              "IPY_MODEL_04160a993756473082f6d27ecfd0c45b"
            ],
            "layout": "IPY_MODEL_6e4791b24c0342fe981bd3d5ce1c2ebc"
          }
        },
        "79225840e5ba45a2970402d891a10f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3238f93207c742be86526a41848e7126",
            "placeholder": "​",
            "style": "IPY_MODEL_8a8146dddf6c4f1e9ffca82b09d18b05",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "d12899ffd89b41729b08647895a7b4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6475e4610e648768c01efe9f5015363",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40b0fb221ae0402a8b7091081a37e0dd",
            "value": 1842767
          }
        },
        "04160a993756473082f6d27ecfd0c45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11119d7a7f3a47be85b5b7c845fe5daa",
            "placeholder": "​",
            "style": "IPY_MODEL_7539a7fb944c4150a341b248407f8944",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 7.52MB/s]"
          }
        },
        "6e4791b24c0342fe981bd3d5ce1c2ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3238f93207c742be86526a41848e7126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a8146dddf6c4f1e9ffca82b09d18b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6475e4610e648768c01efe9f5015363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b0fb221ae0402a8b7091081a37e0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11119d7a7f3a47be85b5b7c845fe5daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7539a7fb944c4150a341b248407f8944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "893a0fb8ee674c7998ebb9833ea43d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_574b2883a5df458b9fb23e3767dd6bc7",
              "IPY_MODEL_e984179a1cc946f596c8d1da17d30bb1",
              "IPY_MODEL_10d987bccde246b1b4400a0e38d1f0c0"
            ],
            "layout": "IPY_MODEL_30ba50ed7b9647308d781ddbe6176f5f"
          }
        },
        "574b2883a5df458b9fb23e3767dd6bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9008ea8465f44d4bf704f27366cd633",
            "placeholder": "​",
            "style": "IPY_MODEL_6468e878570345839c2802e9e8482703",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e984179a1cc946f596c8d1da17d30bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0dfefa8d5af47e086286a5dea082c30",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d9b76f2ac5d4322ae70983487f3fd74",
            "value": 2
          }
        },
        "10d987bccde246b1b4400a0e38d1f0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aaf6b7f28e24e0a94c8762a72de0a2f",
            "placeholder": "​",
            "style": "IPY_MODEL_3f919d6a577642539339ebabb547c4e6",
            "value": " 2/2 [01:24&lt;00:00, 38.57s/it]"
          }
        },
        "30ba50ed7b9647308d781ddbe6176f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9008ea8465f44d4bf704f27366cd633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6468e878570345839c2802e9e8482703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0dfefa8d5af47e086286a5dea082c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9b76f2ac5d4322ae70983487f3fd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aaf6b7f28e24e0a94c8762a72de0a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f919d6a577642539339ebabb547c4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a7368e942d04c3fbcf30dd9cc3e3992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e278854124a4a008a817f3d4217684b",
              "IPY_MODEL_e97b4344f3bf423887c06a091ceea350",
              "IPY_MODEL_3670424649f242f689c3b2773cdc1a70"
            ],
            "layout": "IPY_MODEL_5f4e0d93b0c0407e909e10820a9a00ff"
          }
        },
        "0e278854124a4a008a817f3d4217684b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd7c46c391574e8e83e9ef3a43e57e47",
            "placeholder": "​",
            "style": "IPY_MODEL_777c50be185b49cfae98e020a8439dcf",
            "value": "adapter_model.bin: 100%"
          }
        },
        "e97b4344f3bf423887c06a091ceea350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21e1075674874acca6cbccd25428fc40",
            "max": 639792909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_806e1985eff7452791ba59e735a5d733",
            "value": 639792909
          }
        },
        "3670424649f242f689c3b2773cdc1a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_968a9bdb4372490d975e118baf1400b5",
            "placeholder": "​",
            "style": "IPY_MODEL_62c41bdd6292495d9aac4800fc9d426b",
            "value": " 640M/640M [01:07&lt;00:00, 12.4MB/s]"
          }
        },
        "5f4e0d93b0c0407e909e10820a9a00ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd7c46c391574e8e83e9ef3a43e57e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777c50be185b49cfae98e020a8439dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21e1075674874acca6cbccd25428fc40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806e1985eff7452791ba59e735a5d733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "968a9bdb4372490d975e118baf1400b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c41bdd6292495d9aac4800fc9d426b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seiichiinoue/label-studio-sample/blob/main/train_qlora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 更新記録\n",
        "\n",
        "- 23/10/01: stablelmを学習可能に"
      ],
      "metadata": {
        "id": "l063epBCwzSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 概要\n",
        "\n",
        "[artidoro/qlora](https://github.com/artidoro/qlora)を用いて、llama2をQLoRAでinstruction tuningするコード\n",
        "\n",
        "\n",
        "*   参考実装: https://note.com/npaka/n/na7c631175111\n",
        "*   手順書: https://docs.google.com/document/d/1GIoUtoJFuGAVLfHaWHb4ILX8RLFajb7qmxF-dmoFhak/edit?usp=sharing"
      ],
      "metadata": {
        "id": "Dri0GIW-ubLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 前提\n",
        "\n",
        "https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
        "\n",
        "で利用申請済み（meta form提出 + huggingface hubでsubmit）"
      ],
      "metadata": {
        "id": "y0OIvTbcy4VR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習"
      ],
      "metadata": {
        "id": "5yev4PUalB1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "利用したいベースLLMモデルを指定"
      ],
      "metadata": {
        "id": "JK_Nchho18SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = 'meta-llama/Llama-2-7b-chat-hf' #@param [\"meta-llama/Llama-2-7b-chat-hf\", \"stabilityai/japanese-stablelm-base-alpha-7b\"] {allow-input: true}"
      ],
      "metadata": {
        "id": "K35WekgY1HEr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "メモ:\n",
        "- \"meta-llama/Llama-2-7b-hf: 学習時ロスゼロ問題が生じる\n",
        "- \"elyza/ELYZA-japanese-Llama-2-7b\": RAMが足りない"
      ],
      "metadata": {
        "id": "8G_Q4ONHyO97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "利用したいデータセットを指定"
      ],
      "metadata": {
        "id": "DEBPEaxI15rH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_name = 'databricks-dolly-15k-ja' #@param [\"databricks-dolly-15k-ja\", \"hh-rlhf-49k-ja\"] {allow-input: true}\n",
        "dataset_name = '/content/drive/MyDrive/llama2_qlora/data/label-studio_output.json'  # convert.pyで出力したやつ"
      ],
      "metadata": {
        "id": "UqNsiIx11hJ9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルごとに必要な設定\n",
        "tokenizer_name = None\n",
        "variant = None\n",
        "bits = 4\n",
        "per_device_train_batch_size = 4\n",
        "\n",
        "if model_name_or_path == 'stabilityai/japanese-stablelm-base-alpha-7b':\n",
        "  tokenizer_name = \"novelai/nerdstash-tokenizer-v1\"\n",
        "  # pytorch_model.int8.binをロードするための設定\n",
        "  variant = \"int8\"\n",
        "  bits = 8\n",
        "  # Colab freeだと2以下にしないとVRAMが足りない\n",
        "  per_device_train_batch_size = 2"
      ],
      "metadata": {
        "id": "kGONfhXNxDDs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Driveマウント\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j8QozUXnHVV",
        "outputId": "b4145075-f211-400c-dc1b-b0bca9938d61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 作業フォルダへの移動\n",
        "import os\n",
        "os.makedirs(\"/content/drive/My Drive/llama2_qlora\", exist_ok=True)\n",
        "%cd \"/content/drive/My Drive/llama2_qlora\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8_zg5uGnWX8",
        "outputId": "c7c97800-8676-4167-833e-de040a4e67fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/llama2_qlora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルのチェックポイントのドライブ保存先相対パス\n",
        "output_dir = \"./results/qlora\""
      ],
      "metadata": {
        "id": "aoC9I0zJKTOE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUjLD4kvlane",
        "outputId": "863fa4e6-200a-42d6-af99-154070132283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qlora_ja'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 42 (delta 15), reused 28 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (42/42), 16.94 KiB | 1.30 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "%rm -rf qlora_ja\n",
        "!git clone https://github.com/Sosuke115/qlora_ja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# パッケージのインストール\n",
        "!pip install -U -r qlora_ja/qlora/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2w08drvrrQ5",
        "outputId": "7f7b33ea-76e8-4170-f38b-749ea5dfeaed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes==0.40.0 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 1)) (0.40.0)\n",
            "Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 2)) (4.31.0)\n",
            "Requirement already satisfied: peft==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 3)) (0.4.0)\n",
            "Requirement already satisfied: accelerate==0.21.0 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 4)) (0.21.0)\n",
            "Requirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: evaluate==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 6)) (0.4.0)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 8)) (0.1.99)\n",
            "Requirement already satisfied: wandb==0.15.3 in /usr/local/lib/python3.10/dist-packages (from -r qlora_ja/qlora/requirements.txt (line 9)) (0.15.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (2.0.1+cu118)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (2.14.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (2023.6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (0.18.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r qlora_ja/qlora/requirements.txt (line 7)) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r qlora_ja/qlora/requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r qlora_ja/qlora/requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (3.1.37)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (1.31.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (3.8.5)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (4.0.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r qlora_ja/qlora/requirements.txt (line 2)) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (16.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0->-r qlora_ja/qlora/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.3->-r qlora_ja/qlora/requirements.txt (line 9)) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r qlora_ja/qlora/requirements.txt (line 3)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFaceのログイン\n",
        "# Add token as git credential? (Y/n) はnで良い\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBZvtI7Cwesk",
        "outputId": "5ac037ce-253c-4568-b9b8-3e3c35f1fd4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# A100だと--bf16が使える\n",
        "# kunishou/databricks-dolly-15k-ja: 1h 15mほど\n",
        "# hh-rlhf-49k-ja: 1h 18min 44sほど\n",
        "# チェックポイントをドライブに保存するため、ドライブのストレージ容量に注意\n",
        "# 学習ログの確認にwandbを利用する場合は別で登録が必要\n",
        "\n",
        "# 学習の実行\n",
        "!python qlora_ja/qlora/qlora.py \\\n",
        "    --model_name $model_name_or_path \\\n",
        "    --output_dir $output_dir \\\n",
        "    --dataset $dataset_name \\\n",
        "    --dataset_format \"alpaca\" \\\n",
        "    --max_steps 500 \\\n",
        "    --use_auth \\\n",
        "    --logging_steps 10 \\\n",
        "    --save_strategy steps \\\n",
        "    --data_seed 42 \\\n",
        "    --save_steps 100 \\\n",
        "    --save_total_limit 40 \\\n",
        "    --max_new_tokens 32 \\\n",
        "    --dataloader_num_workers 1 \\\n",
        "    --group_by_length \\\n",
        "    --logging_strategy steps \\\n",
        "    --remove_unused_columns False \\\n",
        "    --do_train \\\n",
        "    --lora_r 64 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_modules all \\\n",
        "    --lora_dropout 0.1 \\\n",
        "    --double_quant \\\n",
        "    --quant_type nf4 \\\n",
        "    --fp16 \\\n",
        "    --bits $bits \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type constant \\\n",
        "    --gradient_checkpointing \\\n",
        "    --source_max_len 16 \\\n",
        "    --target_max_len 512 \\\n",
        "    --per_device_train_batch_size $per_device_train_batch_size \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --eval_steps 50 \\\n",
        "    --learning_rate 0.0002 \\\n",
        "    --adam_beta2 0.999 \\\n",
        "    --max_grad_norm 0.3 \\\n",
        "    --weight_decay 0.0 \\\n",
        "    --seed 42 \\\n",
        "    --use_peft \\\n",
        "    --trust_remote_code True \\\n",
        "    --report_to wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93xZ0pXSp32c",
        "outputId": "11b10dc0-9a72-466a-c1cc-553c15d7d2ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//172.28.0.1'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-1pqa9lnnceysj --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "2023-10-02 18:46:42.616403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(model_name_or_path='meta-llama/Llama-2-7b-chat-hf', tokenizer_name=None, variant=None, trust_remote_code=True, use_auth_token=True, eval_dataset_size=1024, max_train_samples=None, max_eval_samples=None, source_max_len=16, target_max_len=512, dataset='/content/drive/MyDrive/llama2_qlora/data/label-studio_output.json', dataset_format='alpaca', output_dir='./results/qlora', overwrite_output_dir=False, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=<IntervalStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=2, eval_accumulation_steps=None, eval_delay=0, learning_rate=0.0002, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=0.3, num_train_epochs=3.0, max_steps=500, lr_scheduler_type=<SchedulerType.CONSTANT: 'constant'>, warmup_ratio=0.03, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='./results/qlora/runs/Oct02_18-46-47_c8c2464c3594', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=10, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=100, save_total_limit=40, save_safetensors=False, save_on_each_node=False, no_cuda=False, use_mps_device=False, seed=42, data_seed=42, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=True, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=50.0, dataloader_num_workers=1, past_index=-1, run_name='./results/qlora', disable_tqdm=False, remove_unused_columns=False, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], fsdp=[], fsdp_min_num_params=0, fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.PAGED_ADAMW: 'paged_adamw_32bit'>, optim_args=None, adafactor=False, group_by_length=True, length_column_name='length', report_to=['wandb'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, gradient_checkpointing=True, include_inputs_for_metrics=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, xpu_backend=None, sortish_sampler=False, predict_with_generate=False, generation_max_length=None, generation_num_beams=None, generation_config=GenerationConfig {\n",
            "  \"max_new_tokens\": 32,\n",
            "  \"transformers_version\": \"4.31.0\"\n",
            "}\n",
            ", cache_dir=None, train_on_source=False, mmlu_split='eval', mmlu_dataset='mmlu-fs', do_mmlu_eval=False, max_mmlu_samples=None, mmlu_source_max_len=2048, full_finetune=False, adam8bit=False, double_quant=True, quant_type='nf4', bits=4, lora_r=64, lora_alpha=16.0, lora_dropout=0.1, max_memory_MB=80000, distributed_state=Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            ", _n_gpu=1, __cached__setup_devices=device(type='cuda', index=0), deepspeed_plugin=None)\n",
            "loading base model meta-llama/Llama-2-7b-chat-hf...\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100% 2/2 [01:17<00:00, 38.96s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Adding special tokens.\n",
            "adding LoRA modules...\n",
            "1 is set in pretraining_tp\n",
            "loaded model\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 1918.71it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00,  2.39it/s]\n",
            "Generating train split: 6 examples [00:00, 169.22 examples/s]\n",
            "Map: 100% 5/5 [00:00<00:00, 363.68 examples/s]\n",
            "Map: 100% 1/1 [00:00<00:00, 147.32 examples/s]\n",
            "Map: 100% 5/5 [00:00<00:00, 1292.30 examples/s]\n",
            "dataset: {'input': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nラクダはなぜ水なしで長く生きられるのか？\\n\\n### Response: ', 'output': 'ラクダは、長時間にわたってエネルギーと水分で満たされた状態を保つために、腰の脂肪を利用しています。'}\n",
            "trainable params: 79953920.0 || all params: 3660328960 || trainable: 2.1843370056007205\n",
            "torch.float32 422326272 0.11537932153507864\n",
            "torch.uint8 3238002688 0.8846206784649213\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "{'loss': 2.2943, 'learning_rate': 0.0002, 'epoch': 10.0}\n",
            "{'loss': 0.2375, 'learning_rate': 0.0002, 'epoch': 20.0}\n",
            "{'loss': 0.0506, 'learning_rate': 0.0002, 'epoch': 30.0}\n",
            "{'loss': 0.0248, 'learning_rate': 0.0002, 'epoch': 40.0}\n",
            "{'loss': 0.0232, 'learning_rate': 0.0002, 'epoch': 50.0}\n",
            "{'loss': 0.0228, 'learning_rate': 0.0002, 'epoch': 60.0}\n",
            "{'loss': 0.0222, 'learning_rate': 0.0002, 'epoch': 70.0}\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 80.0}\n",
            "{'loss': 0.022, 'learning_rate': 0.0002, 'epoch': 90.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 100.0}\n",
            " 20% 100/500 [04:22<17:05,  2.56s/it]Saving PEFT checkpoint...\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 110.0}\n",
            "{'loss': 0.0218, 'learning_rate': 0.0002, 'epoch': 120.0}\n",
            "{'loss': 0.022, 'learning_rate': 0.0002, 'epoch': 130.0}\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 140.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 150.0}\n",
            "{'loss': 0.0217, 'learning_rate': 0.0002, 'epoch': 160.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 170.0}\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 180.0}\n",
            "{'loss': 0.022, 'learning_rate': 0.0002, 'epoch': 190.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 200.0}\n",
            " 40% 200/500 [09:07<13:08,  2.63s/it]Saving PEFT checkpoint...\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 210.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 220.0}\n",
            "{'loss': 0.0218, 'learning_rate': 0.0002, 'epoch': 230.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 240.0}\n",
            "{'loss': 0.0222, 'learning_rate': 0.0002, 'epoch': 250.0}\n",
            "{'loss': 0.022, 'learning_rate': 0.0002, 'epoch': 260.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 270.0}\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 280.0}\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 290.0}\n",
            "{'loss': 0.0222, 'learning_rate': 0.0002, 'epoch': 300.0}\n",
            " 60% 300/500 [13:52<08:36,  2.58s/it]Saving PEFT checkpoint...\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 310.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 320.0}\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 330.0}\n",
            "{'loss': 0.022, 'learning_rate': 0.0002, 'epoch': 340.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 350.0}\n",
            "{'loss': 0.0218, 'learning_rate': 0.0002, 'epoch': 360.0}\n",
            "{'loss': 0.0218, 'learning_rate': 0.0002, 'epoch': 370.0}\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 380.0}\n",
            "{'loss': 0.0218, 'learning_rate': 0.0002, 'epoch': 390.0}\n",
            "{'loss': 0.022, 'learning_rate': 0.0002, 'epoch': 400.0}\n",
            " 80% 400/500 [18:46<04:14,  2.55s/it]Saving PEFT checkpoint...\n",
            "{'loss': 0.0223, 'learning_rate': 0.0002, 'epoch': 410.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 420.0}\n",
            "{'loss': 0.0219, 'learning_rate': 0.0002, 'epoch': 430.0}\n",
            "{'loss': 0.0218, 'learning_rate': 0.0002, 'epoch': 440.0}\n",
            "{'loss': 0.022, 'learning_rate': 0.0002, 'epoch': 450.0}\n",
            "{'loss': 0.0221, 'learning_rate': 0.0002, 'epoch': 460.0}\n",
            "{'loss': 0.0218, 'learning_rate': 0.0002, 'epoch': 470.0}\n",
            "{'loss': 0.022, 'learning_rate': 0.0002, 'epoch': 480.0}\n",
            "{'loss': 0.0224, 'learning_rate': 0.0002, 'epoch': 490.0}\n",
            "{'loss': 0.0222, 'learning_rate': 0.0002, 'epoch': 500.0}\n",
            "100% 500/500 [23:24<00:00,  2.61s/it]Saving PEFT checkpoint...\n",
            "{'train_runtime': 1445.9484, 'train_samples_per_second': 2.766, 'train_steps_per_second': 0.346, 'train_loss': 0.07241898450255393, 'epoch': 500.0}\n",
            "100% 500/500 [23:44<00:00,  2.85s/it]\n",
            "Saving PEFT checkpoint...\n",
            "***** train metrics *****\n",
            "  epoch                    =      500.0\n",
            "  train_loss               =     0.0724\n",
            "  train_runtime            = 0:24:05.94\n",
            "  train_samples_per_second =      2.766\n",
            "  train_steps_per_second   =      0.346\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 500.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0002\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0222\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 3546899128320000.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.07242\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1445.9484\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 2.766\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.346\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/llama2_qlora/wandb/offline-run-20231002_184936-iu4ag77a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231002_184936-iu4ag77a/logs\u001b[0m\n",
            "CPU times: user 9.74 s, sys: 1.42 s, total: 11.2 s\n",
            "Wall time: 27min 8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 推論とhubへのpush"
      ],
      "metadata": {
        "id": "c2Allmdxaaws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# トークナイザーとモデルの読み込み\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    tokenizer_name if tokenizer_name else model_name_or_path,\n",
        "    use_fast=False,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# 3分ほどかかる\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    variant=variant,\n",
        "    quantization_config=BitsAndBytesConfig(\n",
        "        load_in_4bit=bits == 4,\n",
        "        load_in_8bit=bits == 8,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    ),\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622,
          "referenced_widgets": [
            "9219fd49943942f7857b51ac96999671",
            "79225840e5ba45a2970402d891a10f02",
            "d12899ffd89b41729b08647895a7b4c0",
            "04160a993756473082f6d27ecfd0c45b",
            "6e4791b24c0342fe981bd3d5ce1c2ebc",
            "3238f93207c742be86526a41848e7126",
            "8a8146dddf6c4f1e9ffca82b09d18b05",
            "c6475e4610e648768c01efe9f5015363",
            "40b0fb221ae0402a8b7091081a37e0dd",
            "11119d7a7f3a47be85b5b7c845fe5daa",
            "7539a7fb944c4150a341b248407f8944",
            "893a0fb8ee674c7998ebb9833ea43d5d",
            "574b2883a5df458b9fb23e3767dd6bc7",
            "e984179a1cc946f596c8d1da17d30bb1",
            "10d987bccde246b1b4400a0e38d1f0c0",
            "30ba50ed7b9647308d781ddbe6176f5f",
            "f9008ea8465f44d4bf704f27366cd633",
            "6468e878570345839c2802e9e8482703",
            "d0dfefa8d5af47e086286a5dea082c30",
            "3d9b76f2ac5d4322ae70983487f3fd74",
            "2aaf6b7f28e24e0a94c8762a72de0a2f",
            "3f919d6a577642539339ebabb547c4e6"
          ]
        },
        "id": "49X8IQWrafvx",
        "outputId": "e9bad3a9-ed26-4f74-97f2-1d0b2abcec1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('8013'), PosixPath('http')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-1ex9p0ajjwogk --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9219fd49943942f7857b51ac96999671"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "893a0fb8ee674c7998ebb9833ea43d5d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRAの読み込み\n",
        "# 5分くらいかかる\n",
        "# 注: 学習時ロスゼロ問題が生じたときは、ロスがゼロになる前のチェックポイントを読み込めば一応動作は可能\n",
        "checkpoint_path = os.path.join(output_dir, \"checkpoint-500\")\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    os.path.join(checkpoint_path, \"adapter_model\"),\n",
        "    device_map={\"\":0}\n",
        ")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN245uipal5I",
        "outputId": "eae0b86b-db1c-4584-db7b-dae2147bda0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(\n",
              "                in_features=4096, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(\n",
              "                in_features=4096, out_features=11008, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=11008, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (up_proj): Linear4bit(\n",
              "                in_features=4096, out_features=11008, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=11008, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (down_proj): Linear4bit(\n",
              "                in_features=11008, out_features=4096, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=11008, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# プロンプトの準備\n",
        "prompt = \"### Instruction: 富士山とは？\\n\\n### Response: \"\n",
        "\n",
        "# 推論の実行\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gErOnbva3ZV",
        "outputId": "75c207a0-6df8-4878-b046-19d92382df2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction: 富士山とは？\n",
            "\n",
            "### Response: 富士山は、日本の山で最も高く、標高3776m。日本の国章の山の一部をなし、日本の象徴としても知られています。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface hubにpush（※適宜保存先パスを修正してpushしてください）\n",
        "\n",
        "# 自分のアカウントにupする場合\n",
        "upload_hf_hub_path = f\"Llama-2-7b-chat-hf-{dataset_name}-qlora-sft\"\n",
        "# studio-ousia organizationにupする場合\n",
        "# upload_hf_hub_path = f\"studio-ousia/Llama-2-7b-chat-hf-{dataset_name}-qlora-sft\"\n",
        "\n",
        "model.push_to_hub(upload_hf_hub_path)"
      ],
      "metadata": {
        "id": "JfCHIjDMa3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "9a7368e942d04c3fbcf30dd9cc3e3992",
            "0e278854124a4a008a817f3d4217684b",
            "e97b4344f3bf423887c06a091ceea350",
            "3670424649f242f689c3b2773cdc1a70",
            "5f4e0d93b0c0407e909e10820a9a00ff",
            "bd7c46c391574e8e83e9ef3a43e57e47",
            "777c50be185b49cfae98e020a8439dcf",
            "21e1075674874acca6cbccd25428fc40",
            "806e1985eff7452791ba59e735a5d733",
            "968a9bdb4372490d975e118baf1400b5",
            "62c41bdd6292495d9aac4800fc9d426b"
          ]
        },
        "outputId": "01feb346-c07e-4ca3-f6cc-613d17357fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.bin:   0%|          | 0.00/640M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a7368e942d04c3fbcf30dd9cc3e3992"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/studio-ousia/Llama-2-7b-chat-hf-hh-rlhf-49k-ja-qlora-sft/commit/4378b108c1cdfdf461a4ae4d01ebc3eda18928a7', commit_message='Upload model', commit_description='', oid='4378b108c1cdfdf461a4ae4d01ebc3eda18928a7', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習設定情報のみhuggingface hubにpushするコード\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from transformers import TrainingArguments\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "training_args = torch.load(os.path.join(checkpoint_path, \"training_args.bin\"))\n",
        "\n",
        "# TrainingArgumentsオブジェクトを辞書に変換\n",
        "training_args_dict = training_args.to_dict()\n",
        "json_file_path = os.path.join(checkpoint_path, \"training_args.json\")\n",
        "# 辞書をJSONファイルとして保存\n",
        "with open(json_file_path, \"w\") as f:\n",
        "    json.dump(training_args_dict, f)\n",
        "\n",
        "# ユーザートークンの取得\n",
        "token = HfFolder().get_token()\n",
        "# Hugging Face APIの初期化\n",
        "api = HfApi()\n",
        "\n",
        "# ファイルをHugging Face Hubにアップロード\n",
        "url = api.upload_file(\n",
        "    token=token,\n",
        "    path_or_fileobj=json_file_path,\n",
        "    repo_id=upload_hf_hub_path,\n",
        "    path_in_repo=\"training_args.json\"  # この名前でHugging Face Hubに保存される\n",
        ")\n",
        "\n",
        "# 補足\n",
        "# 目的: QLoRAでのadapter学習時の学習設定をhubに上げたい\n",
        "# training_argsのみpush to hubはできない: https://discuss.huggingface.co/t/how-to-load-training-args/5720/3\n",
        "# TrainerやRepositoryを利用する方法も厄介そう\n",
        "# 上記理由で本セルのようなhuggingface APIを利用したコードを書いている（がもっと良い方法ありそう）"
      ],
      "metadata": {
        "id": "De6uf0X2OS9w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}